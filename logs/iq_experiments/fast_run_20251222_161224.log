python3 -u main.py $IQ --model agem --expt_name all_agem --n_memories 5192 --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.03 --glances 1 --memory_strength 0.5 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model eralg4 --expt_name all_eralg4 --memories 5192 --batch_size 128 --n_epochs $N_EPOCHS --replay_batch_size 64 
                    --lr 0.03 --glances 1 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model icarl --expt_name all_icarl --n_memories 5192 --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.03 --glances 1 --memory_strength 1.0 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --grad_clip_norm 5.0 --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model gem --expt_name all_gem --n_memories 512 --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.03 --glances 1 --memory_strength 0.5 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --grad_clip_norm 5.0 --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model ewc --expt_name all_ewc --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.03 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model lwf --expt_name all_lwf --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.001 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model packnet --expt_name all_packnet --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.01 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model rwalk --expt_name all_rwalk --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.001 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model si --expt_name all_si --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.001 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model hat --expt_name all_hat --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.0005 --gamma 0.75 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --grad_clip_norm 10.0 --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model ctn --expt_name all_ctn --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --increment 5 
                    --ctn_n_memories 5192 --ctn_lr 0.01 --ctn_beta 0.05 --ctn_inner_steps 2 --ctn_n_meta 2 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model er_ring --expt_name all_erring --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --lr 0.03 --increment 5 
                    --bcl_n_memories 5192 --bcl_temperature 2.0 --bcl_memory_strength 1.0 --bcl_inner_steps 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model ucl_bresnet --expt_name all_ucl_bresnet --batch_size 64 --n_epochs $N_EPOCHS 
                    --lr 0.001 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_lamaml --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --opt_lr 0.25 --alpha_init 0.1 --opt_wt 0.1 --glances 1 --increment 5 
                    --cifar_batches 5 --learn_lr --log_every 3125 --second_order --class_order random 
                    --seed $SEED --grad_clip_norm 1.0 --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_lamaml_sync --memories 1024 --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --opt_lr 0.35 --alpha_init 0.1 --opt_wt 0.1 --glances 1 --increment 5 
                    --cifar_batches 5 --learn_lr --sync_update --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_cmaml --memories 1024 --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --opt_lr 0.35 --alpha_init 0.075 --opt_wt 0.075 --glances 1 --increment 5 
                    --cifar_batches 5 --sync_update --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model meralg1 --expt_name all_meralg1 --batch_size 128 --memories 5192 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --lr 0.1 --beta 0.1 --gamma 1.0 --batches_per_example 10 --increment 5 
                    --log_every 3125 --grad_clip_norm 10.0 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model meta-bgd --expt_name all_meta-bgd --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --alpha_init 0.1 --glances 1 --increment 5 
                    --cifar_batches 3 --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256 --xav_init --std_init 0.02 --mean_eta 50. --train_mc_iters 2

python3 -u main.py $IQ --model bcl_dual --expt_name bcl_basic_test --data_path data/rff/rfmls 
                    --n_layers 2 --n_hiddens 100 --xav_init --glances 1 --n_epochs 1 
                    --batch_size 64 --replay_batch_size 10 --memories 400 --lr 0.03 
                    --increment 5 --log_every 3125 --class_order random 
                    --seed $SEED --validation 0.2 --samples_per_task 256 --classes_per_it 6 
                    --iterations 5000 --test_batch_size 100000 --n_memories 5192 --memory_strength 1.0 
                    --steps_per_sample 1 --gamma 1.0 --beta 0.1 --batches_per_example 1 
                    --opt_lr 0.1 --opt_wt 0.1 --alpha_init 0.1 --cifar_batches 3 --grad_clip_norm 5.0 
                    --second_order --bcl_n_memories 2000 --bcl_memory_strength 1.0 --bcl_temperature 2.0 
                    --bcl_inner_steps 5 --bcl_n_meta 5 --bcl_adapt_lr 0.1 --train_mc_iters 2 
                    --std_init 0.02 --mean_eta 50.0 --fisher_gamma 0.95 --rln 7 --update_steps 10 
                    --meta_lr 0.001 --update_lr 0.1

Logging quick IQ experiment suite to logs/iq_experiments/fast_run_20251222_161224.log
New Experiment Starting...
Running model:  agem
[STATE 2025-12-22 16:12:26] Experiment 'all_agem' starting with model 'agem' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:12:31] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:12:31] Logging to logs//agem/all_agem-2025-12-22_16-12-31-7363/0
True
Model device: cuda:0
[STATE 2025-12-22 16:12:31] Model initialized on device cuda:0
[STATE 2025-12-22 16:12:31] Invoking continual life experience flow
[STATE 2025-12-22 16:12:31] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:12:31] Starting task 0 (1/2)
[STATE 2025-12-22 16:12:31] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:12:31] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.002781343602909713, 0.17995428361819601] ----
Task 0 Epoch 1/1 | Loss 1.6903 | Train Acc 0.2058 | Val Acc 0.0028 | Epoch Time 4.16s (Eval 3.90s, Train 0.26s)
[STATE 2025-12-22 16:12:36] Task 0 Epoch 1/1 complete: 4.16s total (3.90s eval/0.26s train)
[STATE 2025-12-22 16:12:36] Task 0: running final validation.
[STATE 2025-12-22 16:12:47] Completed task 0 (1/2)
[STATE 2025-12-22 16:12:47] Starting task 1 (2/2)
[STATE 2025-12-22 16:12:47] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:12:47] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.26577380952380947, 0.0224825867350566] ----
Task 1 Epoch 1/1 | Loss 1.8667 | Train Acc 0.1797 | Val Acc 0.0225 | Epoch Time 3.87s (Eval 3.70s, Train 0.17s)
[STATE 2025-12-22 16:12:51] Task 1 Epoch 1/1 complete: 3.87s total (3.70s eval/0.17s train)
[STATE 2025-12-22 16:12:51] Task 1: running final validation.
[STATE 2025-12-22 16:13:02] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.15512498345688905 
 Individual Accuracy: [0.3044715447154471, 0.005778422198331045]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.15512498345688905 
 Individual Accuracy: [0.3044715447154471, 0.005778422198331045]
[STATE 2025-12-22 16:13:02] Saving results to logs//agem/all_agem-2025-12-22_16-12-31-7363/0/results
logs//agem/all_agem-2025-12-22_16-12-31-7363/0/results: {'expt_name': 'all_agem', 'model': 'agem', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.03, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//agem/all_agem-2025-12-22_16-12-31-7363/0', 'tf_dir': 'logs//agem/all_agem-2025-12-22_16-12-31-7363/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 5192, 'memory_strength': 0.5, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.136 0.155 0.019 -0.079 # test: 0.136 0.155 0.019 0.000 # 30.48093056678772
[STATE 2025-12-22 16:13:02] Results saved; total runtime 30.48s
New Experiment Starting...
Running model:  eralg4
[STATE 2025-12-22 16:13:05] Experiment 'all_eralg4' starting with model 'eralg4' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:13:09] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:13:09] Logging to logs//eralg4/all_eralg4-2025-12-22_16-13-09-2497/0
True
Model device: cuda:0
[STATE 2025-12-22 16:13:09] Model initialized on device cuda:0
[STATE 2025-12-22 16:13:09] Invoking continual life experience flow
[STATE 2025-12-22 16:13:09] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:13:09] Starting task 0 (1/2)
[STATE 2025-12-22 16:13:09] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:13:09] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 1.6975 | Train Acc 0.2058 | Val Acc 0.1807 | Epoch Time 4.30s (Eval 3.91s, Train 0.39s)
[STATE 2025-12-22 16:13:13] Task 0 Epoch 1/1 complete: 4.30s total (3.91s eval/0.39s train)
[STATE 2025-12-22 16:13:13] Task 0: running final validation.
[STATE 2025-12-22 16:13:24] Completed task 0 (1/2)
[STATE 2025-12-22 16:13:24] Starting task 1 (2/2)
[STATE 2025-12-22 16:13:24] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:13:24] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.37154471544715434, 0.20241478053131007] ----
Task 1 Epoch 1/1 | Loss 1.8304 | Train Acc 0.1871 | Val Acc 0.2024 | Epoch Time 4.08s (Eval 3.71s, Train 0.36s)
[STATE 2025-12-22 16:13:28] Task 1 Epoch 1/1 complete: 4.08s total (3.71s eval/0.36s train)
[STATE 2025-12-22 16:13:28] Task 1: running final validation.
[STATE 2025-12-22 16:13:40] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.2845409691115122 
 Individual Accuracy: [0.35079607046070455, 0.21828586776231987]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.2845409691115122 
 Individual Accuracy: [0.35079607046070455, 0.21828586776231987]
[STATE 2025-12-22 16:13:40] Saving results to logs//eralg4/all_eralg4-2025-12-22_16-13-09-2497/0/results
logs//eralg4/all_eralg4-2025-12-22_16-13-09-2497/0/results: {'expt_name': 'all_eralg4', 'model': 'eralg4', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 5192, 'lr': 0.03, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//eralg4/all_eralg4-2025-12-22_16-13-09-2497/0', 'tf_dir': 'logs//eralg4/all_eralg4-2025-12-22_16-13-09-2497/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.295 0.285 -0.010 -0.000 # test: 0.295 0.285 -0.010 0.000 # 30.710596561431885
[STATE 2025-12-22 16:13:40] Results saved; total runtime 30.71s
New Experiment Starting...
Running model:  icarl
[STATE 2025-12-22 16:13:42] Experiment 'all_icarl' starting with model 'icarl' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:13:45] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:13:45] Logging to logs//icarl/all_icarl-2025-12-22_16-13-45-9173/0
True
Model device: cuda:0
[STATE 2025-12-22 16:13:46] Model initialized on device cuda:0
[STATE 2025-12-22 16:13:46] Invoking continual life experience flow
[STATE 2025-12-22 16:13:46] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:13:46] Starting task 0 (1/2)
[STATE 2025-12-22 16:13:46] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:13:46] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2623983739837397, 0.0] ----
num_classes 6 nc_per_task 6 0 6
Task 0 Epoch 1/1 | Loss 1.6696 | Train Acc 0.1840 | Val Acc 0.2624 | Epoch Time 1.24s (Eval 0.37s, Train 0.86s)
[STATE 2025-12-22 16:13:47] Task 0 Epoch 1/1 complete: 1.24s total (0.37s eval/0.86s train)
[STATE 2025-12-22 16:13:47] Task 0: running final validation.
[STATE 2025-12-22 16:13:59] Completed task 0 (1/2)
[STATE 2025-12-22 16:13:59] Starting task 1 (2/2)
[STATE 2025-12-22 16:13:59] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:13:59] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.39393961265110217, 0.0] ----
num_classes 6 nc_per_task 6 6 12
Task 1 Epoch 1/1 | Loss 2.7163 | Train Acc 0.1759 | Val Acc 0.0000 | Epoch Time 4.73s (Eval 4.23s, Train 0.50s)
[STATE 2025-12-22 16:14:04] Task 1 Epoch 1/1 complete: 4.73s total (4.23s eval/0.50s train)
[STATE 2025-12-22 16:14:04] Task 1: running final validation.
[STATE 2025-12-22 16:14:37] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.20616694195152152 
 Individual Accuracy: [0.37301412818743307, 0.039319755715609965]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.20616694195152152 
 Individual Accuracy: [0.37301412818743307, 0.039319755715609965]
[STATE 2025-12-22 16:14:37] Saving results to logs//icarl/all_icarl-2025-12-22_16-13-45-9173/0/results
/home/lunet/wsmr11/repos/La-MAML/metrics/metrics.py:68: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword
  data = np.array(result_a)
logs//icarl/all_icarl-2025-12-22_16-13-45-9173/0/results: {'expt_name': 'all_icarl', 'model': 'icarl', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.03, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//icarl/all_icarl-2025-12-22_16-13-45-9173/0', 'tf_dir': 'logs//icarl/all_icarl-2025-12-22_16-13-45-9173/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 5.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 5192, 'memory_strength': 1.0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.217 0.206 -0.010 0.000 # test: 0.217 0.206 -0.010 0.000 # 51.33643174171448
[STATE 2025-12-22 16:14:37] Results saved; total runtime 51.34s
New Experiment Starting...
Running model:  gem
[STATE 2025-12-22 16:14:40] Experiment 'all_gem' starting with model 'gem' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:14:43] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:14:43] Logging to logs//gem/all_gem-2025-12-22_16-14-43-2367/0
True
Model device: cuda:0
[STATE 2025-12-22 16:14:43] Model initialized on device cuda:0
[STATE 2025-12-22 16:14:43] Invoking continual life experience flow
[STATE 2025-12-22 16:14:43] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:14:43] Starting task 0 (1/2)
[STATE 2025-12-22 16:14:43] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:14:43] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.002781343602909713, 0.17995428361819601] ----
Task 0 Epoch 1/1 | Loss 1.6557 | Train Acc 0.2191 | Val Acc 0.0028 | Epoch Time 4.13s (Eval 3.86s, Train 0.27s)
[STATE 2025-12-22 16:14:47] Task 0 Epoch 1/1 complete: 4.13s total (3.86s eval/0.27s train)
[STATE 2025-12-22 16:14:47] Task 0: running final validation.
[STATE 2025-12-22 16:14:58] Completed task 0 (1/2)
[STATE 2025-12-22 16:14:58] Starting task 1 (2/2)
[STATE 2025-12-22 16:14:58] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:14:58] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.29370402632597753, 0.006355542679270713] ----
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/gem.py", line 283, in observe
    ptloss.backward()
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`
New Experiment Starting...
Running model:  ewc
[STATE 2025-12-22 16:15:04] Experiment 'all_ewc' starting with model 'ewc' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:15:07] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:15:07] Logging to logs//ewc/all_ewc-2025-12-22_16-15-07-6956/0
True
Model device: cuda:0
[STATE 2025-12-22 16:15:07] Model initialized on device cuda:0
[STATE 2025-12-22 16:15:07] Invoking continual life experience flow
[STATE 2025-12-22 16:15:07] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:15:07] Starting task 0 (1/2)
[STATE 2025-12-22 16:15:07] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:15:07] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 1.6945 | Train Acc 0.2206 | Val Acc 0.1807 | Epoch Time 4.26s (Eval 3.88s, Train 0.38s)
[STATE 2025-12-22 16:15:12] Task 0 Epoch 1/1 complete: 4.26s total (3.88s eval/0.38s train)
[STATE 2025-12-22 16:15:12] Task 0: running final validation.
[STATE 2025-12-22 16:15:23] Completed task 0 (1/2)
[STATE 2025-12-22 16:15:23] Starting task 1 (2/2)
[STATE 2025-12-22 16:15:23] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:15:23] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.3775406504065041, 0.2030249129716047] ----
Task 1 Epoch 1/1 | Loss 2.1220 | Train Acc 0.1709 | Val Acc 0.2030 | Epoch Time 4.00s (Eval 3.71s, Train 0.29s)
[STATE 2025-12-22 16:15:27] Task 1 Epoch 1/1 complete: 4.00s total (3.71s eval/0.29s train)
[STATE 2025-12-22 16:15:27] Task 1: running final validation.
[STATE 2025-12-22 16:15:38] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.24698152410446092 
 Individual Accuracy: [0.3765752032520326, 0.11738784495688924]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.24698152410446092 
 Individual Accuracy: [0.3765752032520326, 0.11738784495688924]
[STATE 2025-12-22 16:15:38] Saving results to logs//ewc/all_ewc-2025-12-22_16-15-07-6956/0/results
logs//ewc/all_ewc-2025-12-22_16-15-07-6956/0/results: {'expt_name': 'all_ewc', 'model': 'ewc', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.03, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//ewc/all_ewc-2025-12-22_16-15-07-6956/0', 'tf_dir': 'logs//ewc/all_ewc-2025-12-22_16-15-07-6956/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.247 0.247 -0.000 0.000 # test: 0.247 0.247 -0.000 0.000 # 30.738892078399658
[STATE 2025-12-22 16:15:39] Results saved; total runtime 30.74s
New Experiment Starting...
Running model:  lwf
[STATE 2025-12-22 16:15:41] Experiment 'all_lwf' starting with model 'lwf' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:15:44] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:15:44] Logging to logs//lwf/all_lwf-2025-12-22_16-15-44-3647/0
True
Model device: cuda:0
[STATE 2025-12-22 16:15:44] Model initialized on device cuda:0
[STATE 2025-12-22 16:15:44] Invoking continual life experience flow
[STATE 2025-12-22 16:15:44] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:15:44] Starting task 0 (1/2)
[STATE 2025-12-22 16:15:44] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:15:44] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 1.9703 | Train Acc 0.1886 | Val Acc 0.1807 | Epoch Time 4.21s (Eval 3.92s, Train 0.29s)
[STATE 2025-12-22 16:15:48] Task 0 Epoch 1/1 complete: 4.21s total (3.92s eval/0.29s train)
[STATE 2025-12-22 16:15:48] Task 0: running final validation.
[STATE 2025-12-22 16:15:59] Completed task 0 (1/2)
[STATE 2025-12-22 16:15:59] Starting task 1 (2/2)
[STATE 2025-12-22 16:15:59] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:15:59] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2954268292682926, 0.20637424243528021] ----
Task 1 Epoch 1/1 | Loss 2.0720 | Train Acc 0.2816 | Val Acc 0.2064 | Epoch Time 3.94s (Eval 3.69s, Train 0.25s)
[STATE 2025-12-22 16:16:03] Task 1 Epoch 1/1 complete: 3.94s total (3.69s eval/0.25s train)
[STATE 2025-12-22 16:16:03] Task 1: running final validation.
[STATE 2025-12-22 16:16:15] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.2341664162493472 
 Individual Accuracy: [0.3404471544715446, 0.1278856780271498]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.2341664162493472 
 Individual Accuracy: [0.3404471544715446, 0.1278856780271498]
[STATE 2025-12-22 16:16:15] Saving results to logs//lwf/all_lwf-2025-12-22_16-15-44-3647/0/results
logs//lwf/all_lwf-2025-12-22_16-15-44-3647/0/results: {'expt_name': 'all_lwf', 'model': 'lwf', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//lwf/all_lwf-2025-12-22_16-15-44-3647/0', 'tf_dir': 'logs//lwf/all_lwf-2025-12-22_16-15-44-3647/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.212 0.234 0.023 0.002 # test: 0.212 0.234 0.023 0.000 # 30.52635955810547
[STATE 2025-12-22 16:16:15] Results saved; total runtime 30.53s
New Experiment Starting...
Running model:  packnet
[STATE 2025-12-22 16:16:18] Experiment 'all_packnet' starting with model 'packnet' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:16:20] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:16:20] Logging to logs//packnet/all_packnet-2025-12-22_16-16-20-7677/0
True
Model device: cuda:0
[STATE 2025-12-22 16:16:20] Model initialized on device cuda:0
[STATE 2025-12-22 16:16:20] Invoking continual life experience flow
[STATE 2025-12-22 16:16:20] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:16:20] Starting task 0 (1/2)
[STATE 2025-12-22 16:16:20] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:16:20] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.1815040650406504, 0.2545327214742671] ----
Task 0 Epoch 1/1 | Loss 1.7973 | Train Acc 0.1667 | Val Acc 0.1815 | Epoch Time 4.47s (Eval 4.20s, Train 0.27s)
[STATE 2025-12-22 16:16:25] Task 0 Epoch 1/1 complete: 4.47s total (4.20s eval/0.27s train)
[STATE 2025-12-22 16:16:25] Task 0: running final validation.
[STATE 2025-12-22 16:16:37] Completed task 0 (1/2)
[STATE 2025-12-22 16:16:37] Starting task 1 (2/2)
[STATE 2025-12-22 16:16:37] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:16:37] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.1815040650406504, 0.2539830873660042] ----
Task 1 Epoch 1/1 | Loss 1.7924 | Train Acc 0.1563 | Val Acc 0.2540 | Epoch Time 4.32s (Eval 4.04s, Train 0.27s)
[STATE 2025-12-22 16:16:41] Task 1 Epoch 1/1 complete: 4.32s total (4.04s eval/0.27s train)
[STATE 2025-12-22 16:16:41] Task 1: running final validation.
[STATE 2025-12-22 16:16:54] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.19043567360014563 
 Individual Accuracy: [0.18211382113821137, 0.19875752606207986]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.19043567360014563 
 Individual Accuracy: [0.18211382113821137, 0.19875752606207986]
[STATE 2025-12-22 16:16:54] Saving results to logs//packnet/all_packnet-2025-12-22_16-16-20-7677/0/results
logs//packnet/all_packnet-2025-12-22_16-16-20-7677/0/results: {'expt_name': 'all_packnet', 'model': 'packnet', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.01, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//packnet/all_packnet-2025-12-22_16-16-20-7677/0', 'tf_dir': 'logs//packnet/all_packnet-2025-12-22_16-16-20-7677/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.190 0.190 0.000 -0.000 # test: 0.190 0.190 0.000 0.000 # 33.94287610054016
[STATE 2025-12-22 16:16:55] Results saved; total runtime 33.94s
New Experiment Starting...
Running model:  rwalk
[STATE 2025-12-22 16:16:57] Experiment 'all_rwalk' starting with model 'rwalk' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:17:00] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:17:00] Logging to logs//rwalk/all_rwalk-2025-12-22_16-17-00-5978/0
True
Model device: cuda:0
[STATE 2025-12-22 16:17:00] Model initialized on device cuda:0
[STATE 2025-12-22 16:17:00] Invoking continual life experience flow
[STATE 2025-12-22 16:17:00] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:17:00] Starting task 0 (1/2)
[STATE 2025-12-22 16:17:00] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:17:00] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 1.9703 | Train Acc 0.1886 | Val Acc 0.1807 | Epoch Time 4.16s (Eval 3.83s, Train 0.33s)
[STATE 2025-12-22 16:17:04] Task 0 Epoch 1/1 complete: 4.16s total (3.83s eval/0.33s train)
[STATE 2025-12-22 16:17:04] Task 0: running final validation.
[STATE 2025-12-22 16:17:16] Completed task 0 (1/2)
[STATE 2025-12-22 16:17:16] Starting task 1 (2/2)
[STATE 2025-12-22 16:17:16] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:17:16] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2954268292682926, 0.20637424243528021] ----
Task 1 Epoch 1/1 | Loss 1.9274 | Train Acc 0.2816 | Val Acc 0.2064 | Epoch Time 3.94s (Eval 3.74s, Train 0.19s)
[STATE 2025-12-22 16:17:20] Task 1 Epoch 1/1 complete: 3.94s total (3.74s eval/0.19s train)
[STATE 2025-12-22 16:17:20] Task 1: running final validation.
[STATE 2025-12-22 16:17:31] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.22436510279632482 
 Individual Accuracy: [0.242920054200542, 0.20581015139210762]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.22436510279632482 
 Individual Accuracy: [0.242920054200542, 0.20581015139210762]
[STATE 2025-12-22 16:17:31] Saving results to logs//rwalk/all_rwalk-2025-12-22_16-17-00-5978/0/results
logs//rwalk/all_rwalk-2025-12-22_16-17-00-5978/0/results: {'expt_name': 'all_rwalk', 'model': 'rwalk', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//rwalk/all_rwalk-2025-12-22_16-17-00-5978/0', 'tf_dir': 'logs//rwalk/all_rwalk-2025-12-22_16-17-00-5978/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.251 0.224 -0.026 0.002 # test: 0.251 0.224 -0.026 0.000 # 30.489196062088013
[STATE 2025-12-22 16:17:31] Results saved; total runtime 30.49s
New Experiment Starting...
Running model:  si
[STATE 2025-12-22 16:17:34] Experiment 'all_si' starting with model 'si' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:17:36] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:17:36] Logging to logs//si/all_si-2025-12-22_16-17-36-9279/0
True
Model device: cuda:0
[STATE 2025-12-22 16:17:37] Model initialized on device cuda:0
[STATE 2025-12-22 16:17:37] Invoking continual life experience flow
[STATE 2025-12-22 16:17:37] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:17:37] Starting task 0 (1/2)
[STATE 2025-12-22 16:17:37] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:17:37] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 1.9703 | Train Acc 0.1886 | Val Acc 0.1807 | Epoch Time 4.12s (Eval 3.80s, Train 0.33s)
[STATE 2025-12-22 16:17:41] Task 0 Epoch 1/1 complete: 4.12s total (3.80s eval/0.33s train)
[STATE 2025-12-22 16:17:41] Task 0: running final validation.
[STATE 2025-12-22 16:17:52] Completed task 0 (1/2)
[STATE 2025-12-22 16:17:52] Starting task 1 (2/2)
[STATE 2025-12-22 16:17:52] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:17:52] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2954268292682926, 0.20637424243528021] ----
Task 1 Epoch 1/1 | Loss 1.9273 | Train Acc 0.2816 | Val Acc 0.2064 | Epoch Time 3.88s (Eval 3.69s, Train 0.19s)
[STATE 2025-12-22 16:17:56] Task 1 Epoch 1/1 complete: 3.88s total (3.69s eval/0.19s train)
[STATE 2025-12-22 16:17:56] Task 1: running final validation.
[STATE 2025-12-22 16:18:07] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.22436510279632482 
 Individual Accuracy: [0.242920054200542, 0.20581015139210762]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.22436510279632482 
 Individual Accuracy: [0.242920054200542, 0.20581015139210762]
[STATE 2025-12-22 16:18:07] Saving results to logs//si/all_si-2025-12-22_16-17-36-9279/0/results
logs//si/all_si-2025-12-22_16-17-36-9279/0/results: {'expt_name': 'all_si', 'model': 'si', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//si/all_si-2025-12-22_16-17-36-9279/0', 'tf_dir': 'logs//si/all_si-2025-12-22_16-17-36-9279/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.251 0.224 -0.026 0.002 # test: 0.251 0.224 -0.026 0.000 # 30.16821527481079
[STATE 2025-12-22 16:18:07] Results saved; total runtime 30.17s
New Experiment Starting...
Running model:  hat
[STATE 2025-12-22 16:18:10] Experiment 'all_hat' starting with model 'hat' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:18:13] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:18:13] Logging to logs//hat/all_hat-2025-12-22_16-18-13-0220/0
True
Model device: cuda:0
[STATE 2025-12-22 16:18:13] Model initialized on device cuda:0
[STATE 2025-12-22 16:18:13] Invoking continual life experience flow
[STATE 2025-12-22 16:18:13] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:18:13] Starting task 0 (1/2)
[STATE 2025-12-22 16:18:13] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:18:13] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2623983739837397, 0.19372463661516998] ----
Task 0 Epoch 1/1 | Loss 2.2686 | Train Acc 0.1944 | Val Acc 0.2624 | Epoch Time 4.40s (Eval 4.13s, Train 0.28s)
[STATE 2025-12-22 16:18:17] Task 0 Epoch 1/1 complete: 4.40s total (4.13s eval/0.28s train)
[STATE 2025-12-22 16:18:17] Task 0: running final validation.
[STATE 2025-12-22 16:18:29] Completed task 0 (1/2)
[STATE 2025-12-22 16:18:29] Starting task 1 (2/2)
[STATE 2025-12-22 16:18:29] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:18:29] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.2623983739837397, 0.1999999999999995] ----
Task 1 Epoch 1/1 | Loss 2.1662 | Train Acc 0.1667 | Val Acc 0.2000 | Epoch Time 4.01s (Eval 3.82s, Train 0.19s)
[STATE 2025-12-22 16:18:33] Task 1 Epoch 1/1 complete: 4.01s total (3.82s eval/0.19s train)
[STATE 2025-12-22 16:18:33] Task 1: running final validation.
[STATE 2025-12-22 16:18:44] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.23119918699186962 
 Individual Accuracy: [0.2623983739837397, 0.1999999999999995]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.23119918699186962 
 Individual Accuracy: [0.2623983739837397, 0.1999999999999995]
[STATE 2025-12-22 16:18:44] Saving results to logs//hat/all_hat-2025-12-22_16-18-13-0220/0/results
logs//hat/all_hat-2025-12-22_16-18-13-0220/0/results: {'expt_name': 'all_hat', 'model': 'hat', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.0005, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//hat/all_hat-2025-12-22_16-18-13-0220/0', 'tf_dir': 'logs//hat/all_hat-2025-12-22_16-18-13-0220/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 10.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 0.75, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.231 0.231 0.000 0.003 # test: 0.231 0.231 0.000 0.000 # 31.371992588043213
[STATE 2025-12-22 16:18:44] Results saved; total runtime 31.37s
New Experiment Starting...
Running model:  ctn
[STATE 2025-12-22 16:18:47] Experiment 'all_ctn' starting with model 'ctn' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:18:50] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:18:50] Logging to logs//ctn/all_ctn-2025-12-22_16-18-50-1094/0
True
Model device: cuda:0
[STATE 2025-12-22 16:18:50] Model initialized on device cuda:0
[STATE 2025-12-22 16:18:50] Invoking continual life experience flow
[STATE 2025-12-22 16:18:50] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:18:50] Starting task 0 (1/2)
[STATE 2025-12-22 16:18:50] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:18:50] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18211382113821137, 0.2203720865654209] ----
Task 0 Epoch 1/1 | Loss 1.3396 | Train Acc 0.2900 | Val Acc 0.1821 | Epoch Time 6.43s (Eval 3.84s, Train 2.59s)
[STATE 2025-12-22 16:18:56] Task 0 Epoch 1/1 complete: 6.43s total (3.84s eval/2.59s train)
[STATE 2025-12-22 16:18:56] Task 0: running final validation.
[STATE 2025-12-22 16:19:07] Completed task 0 (1/2)
[STATE 2025-12-22 16:19:07] Starting task 1 (2/2)
[STATE 2025-12-22 16:19:07] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:19:07] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.17743902439024384, 0.20237187838985954] ----
Task 1 Epoch 1/1 | Loss 2.1664 | Train Acc 0.3370 | Val Acc 0.2024 | Epoch Time 9.39s (Eval 3.74s, Train 5.65s)
[STATE 2025-12-22 16:19:17] Task 1 Epoch 1/1 complete: 9.39s total (3.74s eval/5.65s train)
[STATE 2025-12-22 16:19:17] Task 1: running final validation.
[STATE 2025-12-22 16:19:28] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.22052459868948288 
 Individual Accuracy: [0.2623983739837397, 0.178650823395226]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.22052459868948288 
 Individual Accuracy: [0.2623983739837397, 0.178650823395226]
[STATE 2025-12-22 16:19:28] Saving results to logs//ctn/all_ctn-2025-12-22_16-18-50-1094/0/results
logs//ctn/all_ctn-2025-12-22_16-18-50-1094/0/results: {'expt_name': 'all_ctn', 'model': 'ctn', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//ctn/all_ctn-2025-12-22_16-18-50-1094/0', 'tf_dir': 'logs//ctn/all_ctn-2025-12-22_16-18-50-1094/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 5192, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.178 0.221 0.042 -0.009 # test: 0.178 0.221 0.042 0.000 # 37.952887535095215
[STATE 2025-12-22 16:19:28] Results saved; total runtime 37.95s
New Experiment Starting...
Running model:  er_ring
[STATE 2025-12-22 16:19:31] Experiment 'all_erring' starting with model 'er_ring' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:19:34] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:19:34] Logging to logs//er_ring/all_erring-2025-12-22_16-19-34-0399/0
True
Model device: cuda:0
[STATE 2025-12-22 16:19:34] Model initialized on device cuda:0
[STATE 2025-12-22 16:19:34] Invoking continual life experience flow
[STATE 2025-12-22 16:19:34] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:19:34] Starting task 0 (1/2)
[STATE 2025-12-22 16:19:34] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:19:34] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 0.9016 | Train Acc 0.3975 | Val Acc 0.1807 | Epoch Time 4.72s (Eval 3.82s, Train 0.90s)
[STATE 2025-12-22 16:19:38] Task 0 Epoch 1/1 complete: 4.72s total (3.82s eval/0.90s train)
[STATE 2025-12-22 16:19:38] Task 0: running final validation.
[STATE 2025-12-22 16:19:50] Completed task 0 (1/2)
[STATE 2025-12-22 16:19:50] Starting task 1 (2/2)
[STATE 2025-12-22 16:19:50] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:19:50] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.3454945799457992, 0.20432970471096065] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/er_ring.py", line 191, in observe
    loss.backward()
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.AcceleratorError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.
New Experiment Starting...
Running model:  ucl_bresnet
[STATE 2025-12-22 16:19:57] Experiment 'all_ucl_bresnet' starting with model 'ucl_bresnet' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:20:00] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:20:00] Logging to logs//ucl_bresnet/all_ucl_bresnet-2025-12-22_16-20-00-1537/0
True
Model device: cuda:0
[STATE 2025-12-22 16:20:00] Model initialized on device cuda:0
[STATE 2025-12-22 16:20:00] Invoking continual life experience flow
[STATE 2025-12-22 16:20:00] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:20:00] Starting task 0 (1/2)
[STATE 2025-12-22 16:20:00] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:20:00] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.08915989159891599, 0.2023703294395582] ----
Task 0 Epoch 1/1 | Loss 2.2265 | Train Acc 0.2491 | Val Acc 0.0892 | Epoch Time 139.02s (Eval 138.68s, Train 0.34s)
[STATE 2025-12-22 16:22:19] Task 0 Epoch 1/1 complete: 139.02s total (138.68s eval/0.34s train)
[STATE 2025-12-22 16:22:19] Task 0: running final validation.
[STATE 2025-12-22 16:29:00] Completed task 0 (1/2)
[STATE 2025-12-22 16:29:00] Starting task 1 (2/2)
[STATE 2025-12-22 16:29:00] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:29:00] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.21670054200542, 0.20405949811686577] ----
Task 1 Epoch 1/1 | Loss 167.5895 | Train Acc 0.1534 | Val Acc 0.2041 | Epoch Time 136.78s (Eval 136.38s, Train 0.40s)
[STATE 2025-12-22 16:31:17] Task 1 Epoch 1/1 complete: 136.78s total (136.38s eval/0.40s train)
[STATE 2025-12-22 16:31:17] Task 1: running final validation.
[STATE 2025-12-22 16:38:00] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.1839364216817477 
 Individual Accuracy: [0.17952235772357716, 0.18835048563991824]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.1860322322473225 
 Individual Accuracy: [0.18431571815718145, 0.18774874633746352]
[STATE 2025-12-22 16:38:00] Saving results to logs//ucl_bresnet/all_ucl_bresnet-2025-12-22_16-20-00-1537/0/results
logs//ucl_bresnet/all_ucl_bresnet-2025-12-22_16-20-00-1537/0/results: {'expt_name': 'all_ucl_bresnet', 'model': 'ucl_bresnet', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 64, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//ucl_bresnet/all_ucl_bresnet-2025-12-22_16-20-00-1537/0', 'tf_dir': 'logs//ucl_bresnet/all_ucl_bresnet-2025-12-22_16-20-00-1537/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.202 0.184 -0.018 0.001 # test: 0.200 0.186 -0.014 0.000 # 1080.1282427310944
[STATE 2025-12-22 16:38:00] Results saved; total runtime 1080.13s
New Experiment Starting...
Running model:  lamaml_cifar
[STATE 2025-12-22 16:38:03] Experiment 'all_lamaml' starting with model 'lamaml_cifar' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:38:06] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:38:06] Logging to logs//lamaml_cifar/all_lamaml-2025-12-22_16-38-06-0185/0
True
Model device: cuda:0
[STATE 2025-12-22 16:38:06] Model initialized on device cuda:0
[STATE 2025-12-22 16:38:06] Invoking continual life experience flow
[STATE 2025-12-22 16:38:06] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:38:06] Starting task 0 (1/2)
[STATE 2025-12-22 16:38:06] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:38:06] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 3.3747 | Train Acc 0.2491 | Val Acc 0.1807 | Epoch Time 6.88s (Eval 3.91s, Train 2.96s)
[STATE 2025-12-22 16:38:13] Task 0 Epoch 1/1 complete: 6.88s total (3.91s eval/2.96s train)
[STATE 2025-12-22 16:38:13] Task 0: running final validation.
[STATE 2025-12-22 16:38:24] Completed task 0 (1/2)
[STATE 2025-12-22 16:38:24] Starting task 1 (2/2)
[STATE 2025-12-22 16:38:24] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:38:24] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18097259754085104, 0.20295233443055996] ----
Task 1 Epoch 1/1 | Loss 4.2175 | Train Acc 0.2088 | Val Acc 0.2030 | Epoch Time 6.89s (Eval 3.79s, Train 3.10s)
[STATE 2025-12-22 16:38:31] Task 1 Epoch 1/1 complete: 6.89s total (3.79s eval/3.10s train)
[STATE 2025-12-22 16:38:31] Task 1: running final validation.
[STATE 2025-12-22 16:38:42] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.1917922413294076 
 Individual Accuracy: [0.17699836222712456, 0.20658612043169064]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.1917922413294076 
 Individual Accuracy: [0.17699836222712456, 0.20658612043169064]
[STATE 2025-12-22 16:38:42] Saving results to logs//lamaml_cifar/all_lamaml-2025-12-22_16-38-06-0185/0/results
logs//lamaml_cifar/all_lamaml-2025-12-22_16-38-06-0185/0/results: {'expt_name': 'all_lamaml', 'model': 'lamaml_cifar', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 5192, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//lamaml_cifar/all_lamaml-2025-12-22_16-38-06-0185/0', 'tf_dir': 'logs//lamaml_cifar/all_lamaml-2025-12-22_16-38-06-0185/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.25, 'opt_wt': 0.1, 'alpha_init': 0.1, 'learn_lr': True, 'sync_update': False, 'grad_clip_norm': 1.0, 'cifar_batches': 5, 'use_old_task_memory': False, 'second_order': True, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.194 0.192 -0.002 0.000 # test: 0.194 0.192 -0.002 0.000 # 36.30124306678772
[STATE 2025-12-22 16:38:42] Results saved; total runtime 36.30s
New Experiment Starting...
Running model:  lamaml_cifar
[STATE 2025-12-22 16:38:45] Experiment 'all_lamaml_sync' starting with model 'lamaml_cifar' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:38:48] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:38:48] Logging to logs//lamaml_cifar/all_lamaml_sync-2025-12-22_16-38-48-0878/0
True
Model device: cuda:0
[STATE 2025-12-22 16:38:48] Model initialized on device cuda:0
[STATE 2025-12-22 16:38:48] Invoking continual life experience flow
[STATE 2025-12-22 16:38:48] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:38:48] Starting task 0 (1/2)
[STATE 2025-12-22 16:38:48] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:38:48] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 3.4399 | Train Acc 0.2567 | Val Acc 0.1807 | Epoch Time 6.89s (Eval 3.99s, Train 2.90s)
[STATE 2025-12-22 16:38:55] Task 0 Epoch 1/1 complete: 6.89s total (3.99s eval/2.90s train)
[STATE 2025-12-22 16:38:55] Task 0: running final validation.
[STATE 2025-12-22 16:39:06] Completed task 0 (1/2)
[STATE 2025-12-22 16:39:06] Starting task 1 (2/2)
[STATE 2025-12-22 16:39:06] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:39:06] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.1406901899919416, 0.20075162910522631] ----
Task 1 Epoch 1/1 | Loss 4.0681 | Train Acc 0.2041 | Val Acc 0.2008 | Epoch Time 6.78s (Eval 3.75s, Train 3.04s)
[STATE 2025-12-22 16:39:13] Task 1 Epoch 1/1 complete: 6.78s total (3.75s eval/3.04s train)
[STATE 2025-12-22 16:39:13] Task 1: running final validation.
[STATE 2025-12-22 16:39:24] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.18161012063811577 
 Individual Accuracy: [0.16571389282796858, 0.19750634844826298]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.18161012063811577 
 Individual Accuracy: [0.16571389282796858, 0.19750634844826298]
[STATE 2025-12-22 16:39:24] Saving results to logs//lamaml_cifar/all_lamaml_sync-2025-12-22_16-38-48-0878/0/results
logs//lamaml_cifar/all_lamaml_sync-2025-12-22_16-38-48-0878/0/results: {'expt_name': 'all_lamaml_sync', 'model': 'lamaml_cifar', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 1024, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//lamaml_cifar/all_lamaml_sync-2025-12-22_16-38-48-0878/0', 'tf_dir': 'logs//lamaml_cifar/all_lamaml_sync-2025-12-22_16-38-48-0878/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.35, 'opt_wt': 0.1, 'alpha_init': 0.1, 'learn_lr': True, 'sync_update': True, 'grad_clip_norm': 2.0, 'cifar_batches': 5, 'use_old_task_memory': False, 'second_order': True, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.169 0.182 0.013 -0.001 # test: 0.169 0.182 0.013 0.000 # 36.45407319068909
[STATE 2025-12-22 16:39:25] Results saved; total runtime 36.45s
New Experiment Starting...
Running model:  lamaml_cifar
[STATE 2025-12-22 16:39:27] Experiment 'all_cmaml' starting with model 'lamaml_cifar' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:39:30] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:39:30] Logging to logs//lamaml_cifar/all_cmaml-2025-12-22_16-39-30-4560/0
True
Model device: cuda:0
[STATE 2025-12-22 16:39:30] Model initialized on device cuda:0
[STATE 2025-12-22 16:39:30] Invoking continual life experience flow
[STATE 2025-12-22 16:39:30] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:39:30] Starting task 0 (1/2)
[STATE 2025-12-22 16:39:30] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:39:30] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 2.8762 | Train Acc 0.2708 | Val Acc 0.1807 | Epoch Time 6.80s (Eval 3.87s, Train 2.93s)
[STATE 2025-12-22 16:39:37] Task 0 Epoch 1/1 complete: 6.80s total (3.87s eval/2.93s train)
[STATE 2025-12-22 16:39:37] Task 0: running final validation.
[STATE 2025-12-22 16:39:48] Completed task 0 (1/2)
[STATE 2025-12-22 16:39:48] Starting task 1 (2/2)
[STATE 2025-12-22 16:39:48] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:39:48] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.13444960802904238, 0.2031276004549126] ----
Task 1 Epoch 1/1 | Loss 3.4915 | Train Acc 0.1991 | Val Acc 0.2031 | Epoch Time 6.77s (Eval 3.70s, Train 3.06s)
[STATE 2025-12-22 16:39:55] Task 1 Epoch 1/1 complete: 6.77s total (3.70s eval/3.06s train)
[STATE 2025-12-22 16:39:55] Task 1: running final validation.
[STATE 2025-12-22 16:40:06] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.17209204535723405 
 Individual Accuracy: [0.1357888114595431, 0.208395279254925]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.17209204535723405 
 Individual Accuracy: [0.1357888114595431, 0.208395279254925]
[STATE 2025-12-22 16:40:06] Saving results to logs//lamaml_cifar/all_cmaml-2025-12-22_16-39-30-4560/0/results
logs//lamaml_cifar/all_cmaml-2025-12-22_16-39-30-4560/0/results: {'expt_name': 'all_cmaml', 'model': 'lamaml_cifar', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 1024, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//lamaml_cifar/all_cmaml-2025-12-22_16-39-30-4560/0', 'tf_dir': 'logs//lamaml_cifar/all_cmaml-2025-12-22_16-39-30-4560/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.35, 'opt_wt': 0.075, 'alpha_init': 0.075, 'learn_lr': False, 'sync_update': True, 'grad_clip_norm': 2.0, 'cifar_batches': 5, 'use_old_task_memory': False, 'second_order': True, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.171 0.172 0.001 0.000 # test: 0.171 0.172 0.001 0.000 # 36.030609369277954
[STATE 2025-12-22 16:40:07] Results saved; total runtime 36.03s
New Experiment Starting...
Running model:  meralg1
[STATE 2025-12-22 16:40:09] Experiment 'all_meralg1' starting with model 'meralg1' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:40:12] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:40:12] Logging to logs//meralg1/all_meralg1-2025-12-22_16-40-12-3903/0
True
Model device: cuda:0
[STATE 2025-12-22 16:40:12] Model initialized on device cuda:0
[STATE 2025-12-22 16:40:12] Invoking continual life experience flow
[STATE 2025-12-22 16:40:12] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:40:12] Starting task 0 (1/2)
[STATE 2025-12-22 16:40:12] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:40:12] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.002781343602909713, 0.17995428361819601] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/meralg1.py", line 214, in observe
    self._apply_meta_update(weights_before, weights_after, self.beta)
  File "/home/lunet/wsmr11/repos/La-MAML/model/meralg1.py", line 128, in _apply_meta_update
    tensor.copy_(base_state[name] + (target_state[name] - base_state[name]) * mix)
KeyError: 'conv1.weight'
New Experiment Starting...
Running model:  meta-bgd
[STATE 2025-12-22 16:40:18] Experiment 'all_meta-bgd' starting with model 'meta-bgd' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-22 16:40:21] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-22 16:40:21] Logging to logs//meta-bgd/all_meta-bgd-2025-12-22_16-40-21-7141/0
True
Model device: cuda:0
[STATE 2025-12-22 16:40:21] Model initialized on device cuda:0
[STATE 2025-12-22 16:40:21] Invoking continual life experience flow
[STATE 2025-12-22 16:40:21] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:40:21] Starting task 0 (1/2)
[STATE 2025-12-22 16:40:21] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:40:21] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.002781343602909713, 0.17995428361819601] ----
Task 0 Epoch 1/1 | Loss 3.5738 | Train Acc 0.2590 | Val Acc 0.0028 | Epoch Time 7.85s (Eval 3.85s, Train 4.00s)
[STATE 2025-12-22 16:40:29] Task 0 Epoch 1/1 complete: 7.85s total (3.85s eval/4.00s train)
[STATE 2025-12-22 16:40:29] Task 0: running final validation.
[STATE 2025-12-22 16:40:40] Completed task 0 (1/2)
[STATE 2025-12-22 16:40:40] Starting task 1 (2/2)
[STATE 2025-12-22 16:40:40] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:40:40] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.0, 0.1999999999999995] ----
Task 1 Epoch 1/1 | Loss 4.5735 | Train Acc 0.1154 | Val Acc 0.2000 | Epoch Time 7.67s (Eval 3.70s, Train 3.97s)
[STATE 2025-12-22 16:40:48] Task 1 Epoch 1/1 complete: 7.67s total (3.70s eval/3.97s train)
[STATE 2025-12-22 16:40:48] Task 1: running final validation.
[STATE 2025-12-22 16:40:59] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.10577393514512921 
 Individual Accuracy: [0.0, 0.21154787029025843]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.10577393514512921 
 Individual Accuracy: [0.0, 0.21154787029025843]
[STATE 2025-12-22 16:40:59] Saving results to logs//meta-bgd/all_meta-bgd-2025-12-22_16-40-21-7141/0/results
logs//meta-bgd/all_meta-bgd-2025-12-22_16-40-21-7141/0/results: {'expt_name': 'all_meta-bgd', 'model': 'meta-bgd', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': True, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 5192, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//meta-bgd/all_meta-bgd-2025-12-22_16-40-21-7141/0', 'tf_dir': 'logs//meta-bgd/all_meta-bgd-2025-12-22_16-40-21-7141/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 256, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': None, 'nc_per_task_list': '', 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.1, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': True, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 2, 'std_init': 0.02, 'mean_eta': 50.0, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1, 'classes_per_task': [6, 6]} # val: 0.106 0.106 0.000 0.010 # test: 0.106 0.106 0.000 0.000 # 37.87837624549866
[STATE 2025-12-22 16:41:00] Results saved; total runtime 37.88s
New Experiment Starting...
Running model:  bcl_dual
[STATE 2025-12-22 16:41:02] Experiment 'bcl_basic_test' starting with model 'bcl_dual' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [2 3 5 7 8]
Loaded task0.npz: Remapped labels: [0 1 2 3 4]. Size: 8400)
Loaded task1.npz: Unique train labels: [0 1 4 6 9]
Loaded task1.npz: Remapped labels: [5 6 7 8 9]. Size: 8400)
Built classes_per_task: [5, 5]
Classes per task: [5, 5]
[STATE 2025-12-22 16:41:04] Loader 'task_incremental_loader' ready: 4096 inputs, 10 outputs, 2 tasks
n_outputs: 10 	n_tasks: 2
[STATE 2025-12-22 16:41:04] Logging to logs//bcl_dual/bcl_basic_test-2025-12-22_16-41-04-8119/0
True
Model device: cuda:0
[STATE 2025-12-22 16:41:04] Model initialized on device cuda:0
[STATE 2025-12-22 16:41:04] Invoking continual life experience flow
[STATE 2025-12-22 16:41:04] Life experience start: 2 tasks queued
[STATE 2025-12-22 16:41:04] Starting task 0 (1/2)
[STATE 2025-12-22 16:41:04] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-22 16:41:04] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.20223174171316582, 0.19551432864298363] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/bcl_dual.py", line 286, in observe
    xval, yval, _, mask_val, list_t, class_sizes_val = self.memory_sampling(tt, valid = True)
  File "/home/lunet/wsmr11/repos/La-MAML/model/bcl_dual.py", line 185, in memory_sampling
    idx = np.random.choice(t* self.n_val,sz, False)
  File "numpy/random/mtrand.pyx", line 1047, in numpy.random.mtrand.RandomState.choice
TypeError: expected a sequence of integers or a single integer, got '10.0'
