python3 -u main.py $IQ --model anml --expt_name all_anml --batch_size 128 --n_epochs 1 
                    --lr 0.001 --glances 1 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 128 
                    --rln 7 --update_steps 10 --meta_lr 0.001 --update_lr 0.1 

python3 -u main.py $IQ --model icarl --expt_name all_icarl --n_memories 200 --batch_size 128 --n_epochs 1 
                    --lr 0.03 --glances 1 --memory_strength 1.0  --increment 5 
                    --log_every 3125 --class_order random  --samples_per_task 2500 
                    --seed $SEED --grad_clip_norm 5.0 --calc_test_accuracy --validation 0.3 --samples_per_task 128

python3 -u main.py $IQ --model gem --expt_name all_gem --n_memories 200 --batch_size 128 --n_epochs 1 
                    --lr 0.03 --glances 1 --memory_strength 0.5   --increment 5 
                    --log_every 3125 --class_order random --samples_per_task 2500 
                    --seed $SEED --grad_clip_norm 5.0 --calc_test_accuracy --validation 0.3 --samples_per_task 128

python3 -u main.py $IQ --model meralg1 --expt_name all_meralg1 --batch_size 128 --memories 200 --replay_batch_size 64 
                    --lr 0.1 --beta 0.1 --gamma 1.0 --batches_per_example 10  --increment 5 
                    --log_every 3125 --grad_clip_norm 10.0 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 128

python3 -u main.py $IQ --model meta-bgd --expt_name all_meta-bgd --memories 200 --batch_size 128 --replay_batch_size 64 --n_epochs 1 
                    --alpha_init 0.1 --glances 1  --increment 5 
                    --cifar_batches 3 --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 128 --xav_init  --std_init 0.02 --mean_eta 50. --train_mc_iters 2

Logging IQ experiment suite to logs/iq_experiments/problem_children_run_20251203_123851.log
New Experiment Starting...
Running model:  anml
[STATE 2025-12-03 12:38:52] Experiment 'all_anml' starting with model 'anml' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]
[STATE 2025-12-03 12:38:57] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-03 12:38:57] Logging to logs//anml/all_anml-2025-12-03_12-38-57-4301/0
True
Model device: cuda:0
[STATE 2025-12-03 12:38:57] Model initialized on device cuda:0
[STATE 2025-12-03 12:38:57] Invoking continual life experience flow
[STATE 2025-12-03 12:38:57] Life experience start: 2 tasks queued
[STATE 2025-12-03 12:38:57] Starting task 0 (1/2)
[STATE 2025-12-03 12:38:57] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:38:57] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.00022694738312209768, 0.021589811155028546] ----
Task 0 Epoch 1/1 | Loss 0.1734 | Train Acc 0.8115 | Val Acc 0.0002 | Epoch Time 193.19s (Eval 45.16s, Train 148.03s)
[STATE 2025-12-03 12:42:10] Task 0 Epoch 1/1 complete: 193.19s total (45.16s eval/148.03s train)
[STATE 2025-12-03 12:42:10] Task 0: running final validation.
[STATE 2025-12-03 12:44:27] Completed task 0 (1/2)
[STATE 2025-12-03 12:44:27] Starting task 1 (2/2)
[STATE 2025-12-03 12:44:27] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:44:27] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.9279878495862575, 0.0] ----
Task 1 Epoch 1/1 | Loss 1.7414 | Train Acc 0.0757 | Val Acc 0.0000 | Epoch Time 194.59s (Eval 45.61s, Train 148.99s)
[STATE 2025-12-03 12:47:42] Task 1 Epoch 1/1 complete: 194.59s total (45.61s eval/148.99s train)
[STATE 2025-12-03 12:47:42] Task 1: running final validation.
[STATE 2025-12-03 12:49:58] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.4582908274478128 
 Individual Accuracy: [0.8685974651723054, 0.04798418972332016]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.4582908274478128 
 Individual Accuracy: [0.8685974651723054, 0.04798418972332016]
[STATE 2025-12-03 12:49:58] Saving results to logs//anml/all_anml-2025-12-03_12-38-57-4301/0/results
logs//anml/all_anml-2025-12-03_12-38-57-4301/0/results: {'expt_name': 'all_anml', 'model': 'anml', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': False, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 20, 'memories': 5120, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//anml/all_anml-2025-12-03_12-38-57-4301/0', 'tf_dir': 'logs//anml/all_anml-2025-12-03_12-38-57-4301/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 128, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': 5, 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.001, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': False, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 5, 'std_init': 0.05, 'mean_eta': 1, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1} # val: 0.488 0.458 -0.030 -0.011 # test: 0.488 0.458 -0.030 0.000 # 661.1641061306
[STATE 2025-12-03 12:49:59] Results saved; total runtime 661.16s
New Experiment Starting...
Running model:  icarl
[STATE 2025-12-03 12:50:01] Experiment 'all_icarl' starting with model 'icarl' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]
[STATE 2025-12-03 12:50:06] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-03 12:50:06] Logging to logs//icarl/all_icarl-2025-12-03_12-50-06-4051/0
True
Model device: cuda:0
[STATE 2025-12-03 12:50:06] Model initialized on device cuda:0
[STATE 2025-12-03 12:50:06] Invoking continual life experience flow
[STATE 2025-12-03 12:50:06] Life experience start: 2 tasks queued
[STATE 2025-12-03 12:50:06] Starting task 0 (1/2)
[STATE 2025-12-03 12:50:06] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:50:06] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.919241646590552, 0.8919631093544137] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 382, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 372, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 218, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/icarl.py", line 259, in observe
    all_labs = torch.LongTensor(np.unique(self.memy.cpu().numpy()))
AttributeError: 'NoneType' object has no attribute 'cpu'
New Experiment Starting...
Running model:  gem
[STATE 2025-12-03 12:50:09] Experiment 'all_gem' starting with model 'gem' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]
[STATE 2025-12-03 12:50:14] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-03 12:50:14] Logging to logs//gem/all_gem-2025-12-03_12-50-14-2562/0
True
Model device: cuda:0
[STATE 2025-12-03 12:50:14] Model initialized on device cuda:0
[STATE 2025-12-03 12:50:14] Invoking continual life experience flow
[STATE 2025-12-03 12:50:14] Life experience start: 2 tasks queued
[STATE 2025-12-03 12:50:14] Starting task 0 (1/2)
[STATE 2025-12-03 12:50:14] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:50:14] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.0002967773471596662, 0.02160737812911726] ----
Task 0 Epoch 1/1 | Loss 1.8389 | Train Acc 0.1250 | Val Acc 0.0003 | Epoch Time 39.69s (Eval 39.53s, Train 0.16s)
[STATE 2025-12-03 12:50:54] Task 0 Epoch 1/1 complete: 39.69s total (39.53s eval/0.16s train)
[STATE 2025-12-03 12:50:54] Task 0: running final validation.
[STATE 2025-12-03 12:52:52] Completed task 0 (1/2)
[STATE 2025-12-03 12:52:52] Starting task 1 (2/2)
[STATE 2025-12-03 12:52:52] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:52:52] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.9189797842254112, 0.0] ----
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 382, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 372, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 218, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/gem.py", line 300, in observe
    ptloss.backward()
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.AcceleratorError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

New Experiment Starting...
Running model:  meralg1
[STATE 2025-12-03 12:53:34] Experiment 'all_meralg1' starting with model 'meralg1' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]
[STATE 2025-12-03 12:53:38] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-03 12:53:38] Logging to logs//meralg1/all_meralg1-2025-12-03_12-53-38-7010/0
True
Model device: cuda:0
[STATE 2025-12-03 12:53:38] Model initialized on device cuda:0
[STATE 2025-12-03 12:53:38] Invoking continual life experience flow
[STATE 2025-12-03 12:53:38] Life experience start: 2 tasks queued
[STATE 2025-12-03 12:53:38] Starting task 0 (1/2)
[STATE 2025-12-03 12:53:38] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:53:38] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.0002967773471596662, 0.02160737812911726] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 382, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 372, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 218, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/meralg1.py", line 204, in observe
    loss = self.bce(prediction, by.unsqueeze(0))
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1310, in forward
    return F.cross_entropy(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/nn/functional.py", line 3462, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
New Experiment Starting...
Running model:  meta-bgd
[STATE 2025-12-03 12:54:20] Experiment 'all_meta-bgd' starting with model 'meta-bgd' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]
[STATE 2025-12-03 12:54:25] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-03 12:54:25] Logging to logs//meta-bgd/all_meta-bgd-2025-12-03_12-54-25-1999/0
True
Model device: cuda:0
[STATE 2025-12-03 12:54:25] Model initialized on device cuda:0
[STATE 2025-12-03 12:54:25] Invoking continual life experience flow
[STATE 2025-12-03 12:54:25] Life experience start: 2 tasks queued
[STATE 2025-12-03 12:54:25] Starting task 0 (1/2)
[STATE 2025-12-03 12:54:25] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:54:25] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.0002967773471596662, 0.02160737812911726] ----
Task 0 Epoch 1/1 | Loss 2.0792 | Train Acc 0.8529 | Val Acc 0.0003 | Epoch Time 41.41s (Eval 39.39s, Train 2.02s)
[STATE 2025-12-03 12:55:06] Task 0 Epoch 1/1 complete: 41.41s total (39.39s eval/2.02s train)
[STATE 2025-12-03 12:55:06] Task 0: running final validation.
[STATE 2025-12-03 12:57:05] Completed task 0 (1/2)
[STATE 2025-12-03 12:57:05] Starting task 1 (2/2)
[STATE 2025-12-03 12:57:05] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-03 12:57:05] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.0, 0.02160737812911726] ----
Task 1 Epoch 1/1 | Loss 2.5989 | Train Acc 0.6936 | Val Acc 0.0216 | Epoch Time 41.41s (Eval 39.44s, Train 1.97s)
[STATE 2025-12-03 12:57:46] Task 1 Epoch 1/1 complete: 41.41s total (39.44s eval/1.97s train)
[STATE 2025-12-03 12:57:46] Task 1: running final validation.
[STATE 2025-12-03 12:59:45] Completed task 1 (2/2)
####Final Validation Accuracy####
Final Results:- 
 Total Accuracy: 0.010882247774100894 
 Individual Accuracy: [0.00015711741908452917, 0.02160737812911726]
####Final Test Accuracy####
Final Results:- 
 Total Accuracy: 0.010882247774100894 
 Individual Accuracy: [0.00015711741908452917, 0.02160737812911726]
[STATE 2025-12-03 12:59:45] Saving results to logs//meta-bgd/all_meta-bgd-2025-12-03_12-54-25-1999/0/results
logs//meta-bgd/all_meta-bgd-2025-12-03_12-54-25-1999/0/results: {'expt_name': 'all_meta-bgd', 'model': 'meta-bgd', 'arch': 'resnet1d', 'n_hiddens': 100, 'n_layers': 2, 'xav_init': True, 'glances': 1, 'n_epochs': 1, 'batch_size': 128, 'replay_batch_size': 64.0, 'memories': 200, 'lr': 0.001, 'cuda': True, 'seed': 0, 'log_every': 3125, 'log_dir': 'logs//meta-bgd/all_meta-bgd-2025-12-03_12-54-25-1999/0', 'tf_dir': 'logs//meta-bgd/all_meta-bgd-2025-12-03_12-54-25-1999/0/tfdir', 'calc_test_accuracy': True, 'state_logging': True, 'data_path': 'data/rff/radar/', 'loader': 'task_incremental_loader', 'samples_per_task': 128, 'shuffle_tasks': False, 'classes_per_it': 4, 'iterations': 5000, 'dataset': 'iq', 'workers': 3, 'validation': 0.3, 'class_order': 'random', 'increment': 5, 'test_batch_size': 100000, 'nc_per_task': 5, 'val_rate': 10, 'opt_lr': 0.1, 'opt_wt': 0.1, 'alpha_init': 0.1, 'learn_lr': False, 'sync_update': False, 'grad_clip_norm': 2.0, 'cifar_batches': 3, 'use_old_task_memory': False, 'second_order': True, 'n_memories': 0, 'memory_strength': 0, 'steps_per_sample': 1, 'gamma': 1.0, 'beta': 1.0, 's': 1, 'batches_per_example': 1, 'bgd_optimizer': 'bgd', 'optimizer_params': '{}', 'train_mc_iters': 2, 'std_init': 0.02, 'mean_eta': 50.0, 'fisher_gamma': 0.95, 'rln': 7, 'update_steps': 10, 'meta_lr': 0.001, 'update_lr': 0.1, 'ctn_lr': 0.01, 'ctn_beta': 0.05, 'ctn_n_meta': 2, 'ctn_inner_steps': 2, 'ctn_temperature': 5, 'ctn_n_memories': 50, 'ctn_alpha_init': 0.1, 'ctn_memory_strength': 0.5, 'ctn_task_emb': 64, 'bcl_n_memories': 2000, 'bcl_memory_strength': 1.0, 'bcl_temperature': 2.0, 'bcl_inner_steps': 5, 'bcl_n_meta': 5, 'bcl_adapt_lr': 0.1} # val: 0.011 0.011 0.000 0.000 # test: 0.011 0.011 0.000 0.000 # 319.9259090423584
[STATE 2025-12-03 12:59:45] Results saved; total runtime 319.93s
