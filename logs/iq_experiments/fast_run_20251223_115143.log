python3 -u main.py $IQ --model gem --expt_name all_gem --n_memories 512 --batch_size 128 --n_epochs $N_EPOCHS 
                    --lr 0.03 --glances 1 --memory_strength 0.5 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --grad_clip_norm 5.0 --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model er_ring --expt_name all_erring --batch_size 128 --replay_batch_size 64 --n_epochs $N_EPOCHS 
                    --lr 0.03 --increment 5 
                    --bcl_n_memories 5192 --bcl_temperature 2.0 --bcl_memory_strength 1.0 --bcl_inner_steps 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task 256

python3 -u main.py $IQ --model bcl_dual --expt_name bcl_basic_test --data_path data/rff/rfmls 
                    --n_layers 2 --n_hiddens 100 --xav_init --glances 1 --n_epochs 1 
                    --batch_size 64 --replay_batch_size 10 --memories 400 --lr 0.03 
                    --increment 5 --log_every 3125 --class_order random 
                    --seed $SEED --validation 0.2 --samples_per_task 256 --classes_per_it 6 
                    --iterations 5000 --test_batch_size 100000 --n_memories 5192 --memory_strength 1.0 
                    --steps_per_sample 1 --gamma 1.0 --beta 0.1 --batches_per_example 1 
                    --opt_lr 0.1 --opt_wt 0.1 --alpha_init 0.1 --cifar_batches 3 --grad_clip_norm 5.0 
                    --second_order --bcl_n_memories 2000 --bcl_memory_strength 1.0 --bcl_temperature 2.0 
                    --bcl_inner_steps 5 --bcl_n_meta 5 --bcl_adapt_lr 0.1 --train_mc_iters 2 
                    --std_init 0.02 --mean_eta 50.0 --fisher_gamma 0.95 --rln 7 --update_steps 10 
                    --meta_lr 0.001 --update_lr 0.1

Logging quick IQ experiment suite to logs/iq_experiments/fast_run_20251223_115143.log
New Experiment Starting...
Running model:  gem
[STATE 2025-12-23 11:51:45] Experiment 'all_gem' starting with model 'gem' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-23 11:51:49] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-23 11:51:49] Logging to logs//gem/all_gem-2025-12-23_11-51-49-2952/0
True
Model device: cuda:0
[STATE 2025-12-23 11:51:49] Model initialized on device cuda:0
[STATE 2025-12-23 11:51:49] Invoking continual life experience flow
[STATE 2025-12-23 11:51:49] Life experience start: 2 tasks queued
[STATE 2025-12-23 11:51:49] Starting task 0 (1/2)
[STATE 2025-12-23 11:51:49] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:51:49] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.002781343602909713, 0.17995428361819601] ----
Task 0 Epoch 1/1 | Loss 1.6557 | Train Acc 0.2191 | Val Acc 0.0028 | Epoch Time 4.07s (Eval 3.80s, Train 0.28s)
[STATE 2025-12-23 11:51:53] Task 0 Epoch 1/1 complete: 4.07s total (3.80s eval/0.28s train)
[STATE 2025-12-23 11:51:53] Task 0: running final validation.
[STATE 2025-12-23 11:52:04] Completed task 0 (1/2)
[STATE 2025-12-23 11:52:04] Starting task 1 (2/2)
[STATE 2025-12-23 11:52:04] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:52:04] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.29370402632597753, 0.006355542679270713] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/gem.py", line 282, in observe
    raise ValueError(
ValueError: GEM replay target out of range for task 0: min=0, max=135218469893792, classes=6, offset=(0,6)
New Experiment Starting...
Running model:  er_ring
[STATE 2025-12-23 11:52:10] Experiment 'all_erring' starting with model 'er_ring' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 32208)
Built classes_per_task: [6, 6]
Classes per task: [6, 6]
[STATE 2025-12-23 11:52:13] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-23 11:52:13] Logging to logs//er_ring/all_erring-2025-12-23_11-52-13-7367/0
True
Model device: cuda:0
[STATE 2025-12-23 11:52:13] Model initialized on device cuda:0
[STATE 2025-12-23 11:52:13] Invoking continual life experience flow
[STATE 2025-12-23 11:52:13] Life experience start: 2 tasks queued
[STATE 2025-12-23 11:52:13] Starting task 0 (1/2)
[STATE 2025-12-23 11:52:13] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:52:13] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.18073627668559392, 0.20250395400770593] ----
Task 0 Epoch 1/1 | Loss 0.9016 | Train Acc 0.3975 | Val Acc 0.1807 | Epoch Time 4.76s (Eval 3.85s, Train 0.90s)
[STATE 2025-12-23 11:52:18] Task 0 Epoch 1/1 complete: 4.76s total (3.85s eval/0.90s train)
[STATE 2025-12-23 11:52:18] Task 0: running final validation.
[STATE 2025-12-23 11:52:29] Completed task 0 (1/2)
[STATE 2025-12-23 11:52:29] Starting task 1 (2/2)
[STATE 2025-12-23 11:52:29] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:52:29] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.3454945799457992, 0.20432970471096065] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/er_ring.py", line 195, in observe
    raise ValueError(
ValueError: Replay target out of range: min=4216233945081254511, max=4216233945081254511, class_count=6, sizes=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
New Experiment Starting...
Running model:  bcl_dual
[STATE 2025-12-23 11:52:37] Experiment 'bcl_basic_test' starting with model 'bcl_dual' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [2 3 5 7 8]
Loaded task0.npz: Remapped labels: [0 1 2 3 4]. Size: 8400)
Loaded task1.npz: Unique train labels: [0 1 4 6 9]
Loaded task1.npz: Remapped labels: [5 6 7 8 9]. Size: 8400)
Built classes_per_task: [5, 5]
Classes per task: [5, 5]
[STATE 2025-12-23 11:52:39] Loader 'task_incremental_loader' ready: 4096 inputs, 10 outputs, 2 tasks
n_outputs: 10 	n_tasks: 2
[STATE 2025-12-23 11:52:39] Logging to logs//bcl_dual/bcl_basic_test-2025-12-23_11-52-39-0467/0
True
Model device: cuda:0
[STATE 2025-12-23 11:52:39] Model initialized on device cuda:0
[STATE 2025-12-23 11:52:39] Invoking continual life experience flow
[STATE 2025-12-23 11:52:39] Life experience start: 2 tasks queued
[STATE 2025-12-23 11:52:39] Starting task 0 (1/2)
[STATE 2025-12-23 11:52:39] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:52:39] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.20223174171316582, 0.19551432864298363] ----
Task 0 Epoch 1/1 | Loss 6.3001 | Train Acc 0.6802 | Val Acc 0.2022 | Epoch Time 8.62s (Eval 1.21s, Train 7.42s)
[STATE 2025-12-23 11:52:47] Task 0 Epoch 1/1 complete: 8.62s total (1.21s eval/7.42s train)
[STATE 2025-12-23 11:52:47] Task 0: running final validation.
[STATE 2025-12-23 11:52:50] Completed task 0 (1/2)
[STATE 2025-12-23 11:52:50] Starting task 1 (2/2)
[STATE 2025-12-23 11:52:50] Task 1 Epoch 1/1: entering train loop
[STATE 2025-12-23 11:52:50] Task 1 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.24564549297865426, 0.21452540732210504] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 395, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 385, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 221, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/bcl_dual.py", line 273, in observe
    xx, yy, feat, mask, list_t, class_sizes = self.memory_sampling(t)
  File "/home/lunet/wsmr11/repos/La-MAML/model/bcl_dual.py", line 194, in memory_sampling
    idx = np.random.choice(t* self.n_memories,sz, False)
  File "numpy/random/mtrand.pyx", line 1047, in numpy.random.mtrand.RandomState.choice
TypeError: expected a sequence of integers or a single integer, got '10.0'
