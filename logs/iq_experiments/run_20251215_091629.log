python3 -u main.py $IQ --model lwf --expt_name all_lwf --batch_size 128 --n_epochs 50 
                    --lr 0.001 --increment 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

python3 -u main.py $IQ --model meralg1 --expt_name all_meralg1 --batch_size 128 --memories 5192 --replay_batch_size 64 
                    --lr 0.1 --beta 0.1 --gamma 1.0 --batches_per_example 10  --increment 5 
                    --log_every 3125 --grad_clip_norm 10.0 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

python3 -u main.py $IQ --model meta-bgd --expt_name all_meta-bgd --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --alpha_init 0.1 --glances 1  --increment 5 
                    --cifar_batches 3 --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1 --xav_init  --std_init 0.02 --mean_eta 50. --train_mc_iters 2

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_lamaml --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --opt_lr 0.25 --alpha_init 0.1 --opt_wt 0.1 --glances 1  --increment 5 
                    --cifar_batches 5 --learn_lr --log_every 3125 --second_order --class_order random 
                    --seed $SEED --grad_clip_norm 1.0 --calc_test_accuracy --validation 0.3 --samples_per_task -1

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_lamaml_sync --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --opt_lr 0.35 --alpha_init 0.1 --opt_wt 0.1 --glances 1  --increment 5 
                    --cifar_batches 5 --learn_lr --sync_update --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

python3 -u main.py $IQ --model lamaml_cifar --expt_name all_cmaml --memories 5192 --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --opt_lr 0.35 --alpha_init 0.075 --opt_wt 0.075 --glances 1  --increment 5 
                    --cifar_batches 5 --sync_update --log_every 3125 --second_order --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

Logging IQ experiment suite to logs/iq_experiments/run_20251215_091629.log
New Experiment Starting...
Running model:  lwf
[STATE 2025-12-15 09:16:31] Experiment 'all_lwf' starting with model 'lwf' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 190940)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 379500)
[STATE 2025-12-15 09:16:34] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-15 09:16:34] Logging to logs//lwf/all_lwf-2025-12-15_09-16-34-0465/0
True
Model device: cuda:0
[STATE 2025-12-15 09:16:34] Model initialized on device cuda:0
[STATE 2025-12-15 09:16:34] Invoking continual life experience flow
[STATE 2025-12-15 09:16:34] Life experience start: 2 tasks queued
[STATE 2025-12-15 09:16:34] Starting task 0 (1/2)
[STATE 2025-12-15 09:16:34] Task 0 Epoch 1/50: entering train loop
[STATE 2025-12-15 09:16:34] Task 0 Epoch 1/50 Iter 0: running validation
---- Eval at Epoch 0: [0.19910249530421933, 0.021764828942551235] ----
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 381, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 371, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
                                                                           ^^^^^^^^^^^^^^^^
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 217, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lunet/wsmr11/repos/La-MAML/model/lwf.py", line 126, in observe
    loss = loss_ce + self.distill_lambda * distill_loss
                     ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~
torch.AcceleratorError: CUDA error: device-side assert triggered
Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

New Experiment Starting...
Running model:  meralg1
[STATE 2025-12-15 09:17:30] Experiment 'all_meralg1' starting with model 'meralg1' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 190940)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 379500)
[STATE 2025-12-15 09:17:33] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-15 09:17:33] Logging to logs//meralg1/all_meralg1-2025-12-15_09-17-33-4359/0
True
Model device: cuda:0
[STATE 2025-12-15 09:17:33] Model initialized on device cuda:0
[STATE 2025-12-15 09:17:33] Invoking continual life experience flow
[STATE 2025-12-15 09:17:33] Life experience start: 2 tasks queued
[STATE 2025-12-15 09:17:33] Starting task 0 (1/2)
[STATE 2025-12-15 09:17:33] Task 0 Epoch 1/1: entering train loop
[STATE 2025-12-15 09:17:33] Task 0 Epoch 1/1 Iter 0: running validation
---- Eval at Epoch 0: [0.001181744285715008, 0.019647215794938975] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 381, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 371, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
                                                                           ^^^^^^^^^^^^^^^^
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 217, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/lunet/wsmr11/repos/La-MAML/model/meralg1.py", line 212, in observe
    self._apply_meta_update(weights_before, weights_after, self.beta)
  File "/home/lunet/wsmr11/repos/La-MAML/model/meralg1.py", line 126, in _apply_meta_update
    tensor.copy_(base_state[name] + (target_state[name] - base_state[name]) * mix)
                 ~~~~~~~~~~^^^^^^
KeyError: 'conv1.weight'
New Experiment Starting...
Running model:  meta-bgd
[STATE 2025-12-15 09:18:30] Experiment 'all_meta-bgd' starting with model 'meta-bgd' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 190940)
Loaded task1.npz: Unique train labels: [ 0  6  7  8  9 10]
Loaded task1.npz: Remapped labels: [ 6  7  8  9 10 11]. Size: 379500)
[STATE 2025-12-15 09:18:33] Loader 'task_incremental_loader' ready: 1024 inputs, 12 outputs, 2 tasks
n_outputs: 12 	n_tasks: 2
[STATE 2025-12-15 09:18:33] Logging to logs//meta-bgd/all_meta-bgd-2025-12-15_09-18-33-1464/0
True
Model device: cuda:0
[STATE 2025-12-15 09:18:33] Model initialized on device cuda:0
[STATE 2025-12-15 09:18:33] Invoking continual life experience flow
[STATE 2025-12-15 09:18:33] Life experience start: 2 tasks queued
[STATE 2025-12-15 09:18:33] Starting task 0 (1/2)
[STATE 2025-12-15 09:18:33] Task 0 Epoch 1/50: entering train loop
[STATE 2025-12-15 09:18:33] Task 0 Epoch 1/50 Iter 0: running validation
---- Eval at Epoch 0: [0.001181744285715008, 0.019647215794938975] ----
Task 0 Epoch 1/50 | Loss 0.1639 | Train Acc 0.7529 | Val Acc 0.0012 | Epoch Time 3155.31s (Eval 53.59s, Train 3101.72s)
[STATE 2025-12-15 10:11:08] Task 0 Epoch 1/50 complete: 3155.31s total (53.59s eval/3101.72s train)
[STATE 2025-12-15 10:11:08] Task 0 Epoch 2/50: entering train loop
Task 0 Epoch 2/50 | Loss 0.0313 | Train Acc 0.9072 | Val Acc 0.0012 | Epoch Time 3108.79s (Eval 0.00s, Train 3108.79s)
[STATE 2025-12-15 11:02:57] Task 0 Epoch 2/50 complete: 3108.79s total (0.00s eval/3108.79s train)
[STATE 2025-12-15 11:02:57] Task 0 Epoch 3/50: entering train loop
Task 0 Epoch 3/50 | Loss 0.0229 | Train Acc 0.9357 | Val Acc 0.0012 | Epoch Time 3097.61s (Eval 0.00s, Train 3097.61s)
[STATE 2025-12-15 11:54:35] Task 0 Epoch 3/50 complete: 3097.61s total (0.00s eval/3097.61s train)
[STATE 2025-12-15 11:54:35] Task 0 Epoch 4/50: entering train loop
Task 0 Epoch 4/50 | Loss 0.0207 | Train Acc 0.9425 | Val Acc 0.0012 | Epoch Time 3096.69s (Eval 0.00s, Train 3096.69s)
[STATE 2025-12-15 12:46:11] Task 0 Epoch 4/50 complete: 3096.69s total (0.00s eval/3096.69s train)
[STATE 2025-12-15 12:46:11] Task 0 Epoch 5/50: entering train loop
Task 0 Epoch 5/50 | Loss 0.0173 | Train Acc 0.9514 | Val Acc 0.0012 | Epoch Time 3103.81s (Eval 0.00s, Train 3103.81s)
[STATE 2025-12-15 13:37:55] Task 0 Epoch 5/50 complete: 3103.81s total (0.00s eval/3103.81s train)
[STATE 2025-12-15 13:37:55] Task 0 Epoch 6/50: entering train loop
Task 0 Epoch 6/50 | Loss 0.0160 | Train Acc 0.9578 | Val Acc 0.0012 | Epoch Time 3127.19s (Eval 0.00s, Train 3127.19s)
[STATE 2025-12-15 14:30:02] Task 0 Epoch 6/50 complete: 3127.19s total (0.00s eval/3127.19s train)
[STATE 2025-12-15 14:30:02] Task 0 Epoch 7/50: entering train loop
Task 0 Epoch 7/50 | Loss 0.0140 | Train Acc 0.9593 | Val Acc 0.0012 | Epoch Time 3107.61s (Eval 0.00s, Train 3107.61s)
[STATE 2025-12-15 15:21:50] Task 0 Epoch 7/50 complete: 3107.61s total (0.00s eval/3107.61s train)
[STATE 2025-12-15 15:21:50] Task 0 Epoch 8/50: entering train loop
