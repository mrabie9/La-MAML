python3 -u main.py $IQ --model ctn --expt_name all_ctn --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --increment 5 
                    --ctn_n_memories 5192 --ctn_lr 0.01 --ctn_beta 0.05 --ctn_inner_steps 2 --ctn_n_meta 2 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

python3 -u main.py $IQ --model er_ring --expt_name all_erring --batch_size 128 --replay_batch_size 64 --n_epochs 50 
                    --lr 0.03 --increment 5 
                    --bcl_n_memories 5192 --bcl_temperature 2.0 --bcl_memory_strength 1.0 --bcl_inner_steps 5 
                    --log_every 3125 --class_order random 
                    --seed $SEED --calc_test_accuracy --validation 0.3 --samples_per_task -1

Logging IQ experiment suite to logs/iq_experiments/run_20251221_172121.log
New Experiment Starting...
Running model:  ctn
[STATE 2025-12-21 17:21:23] Experiment 'all_ctn' starting with model 'ctn' (seed 0)
Set seed 0
Loaded task0.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task0.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
Loaded task1.npz: Unique train labels: [0 1 2 3 4 5]
Loaded task1.npz: Remapped labels: [0 1 2 3 4 5]. Size: 17294)
[STATE 2025-12-21 17:21:26] Loader 'task_incremental_loader' ready: 1024 inputs, 6 outputs, 2 tasks
n_outputs: 6 	n_tasks: 2
[STATE 2025-12-21 17:21:26] Logging to logs//ctn/all_ctn-2025-12-21_17-21-26-6867/0
True
Model device: cuda:0
[STATE 2025-12-21 17:21:26] Model initialized on device cuda:0
[STATE 2025-12-21 17:21:26] Invoking continual life experience flow
[STATE 2025-12-21 17:21:26] Life experience start: 2 tasks queued
[STATE 2025-12-21 17:21:26] Starting task 0 (1/2)
[STATE 2025-12-21 17:21:26] Task 0 Epoch 1/50: entering train loop
[STATE 2025-12-21 17:21:26] Task 0 Epoch 1/50 Iter 0: running validation
---- Eval at Epoch 0: [0.22774727176922438, 0.16935975609756088] ----
Traceback (most recent call last):
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 381, in <module>
    main()
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 371, in main
    result_val_t, result_val_a, result_test_t, result_test_a, spent_time = life_experience(
  File "/home/lunet/wsmr11/repos/La-MAML/main.py", line 217, in life_experience
    loss, tr_acc = model.observe(Variable(v_x), Variable(v_y), task_info["task"])
  File "/home/lunet/wsmr11/repos/La-MAML/model/ctn.py", line 272, in observe
    grads = torch.autograd.grad(loss, self.net.base_param(), create_graph=True)
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 503, in grad
    result = _engine_run_backward(
  File "/home/lunet/wsmr11/repos/La-MAML/la-maml_env/lib/python3.10/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:245: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.
